import gradio as gr
from typing import Iterator
# from demo_2 import run
import re
import copy
import time
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
import torch
from modelscope import AutoModelForCausalLM, AutoTokenizer
import json
from tqdm import tqdm

device = "cuda"

tokenizer = AutoTokenizer.from_pretrained("/home/sda/wangzhijun/Doctor_1st/MyWorks/checkpoint-45000", trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    "/home/sda/wangzhijun/Doctor_1st/MyWorks/checkpoint-45000",
    torch_dtype=torch.bfloat16,
    low_cpu_mem_usage=True,
    trust_remote_code=True
).eval().to(device)


ROLE_TEMP = 0
# DESCRIPTION = """
# <br>
# <div align="center" style="font-size: 13pt;">
# ğŸ¤— <a href="https://huggingface.co/DUTIR-BioNLP/Taiyi-LLM" rel="nofollow">Hugging Face</a>&nbsp;&nbsp; | &nbsp;&nbsp;ğŸ¤– <a href="" rel="nofollow">ModelScope</a>&nbsp;&nbsp; | &nbsp;&nbsp;<img src="https://pic.imgdb.cn/item/651401a4c458853aef46f7f5.png" style="width: 13pt; display: inline-block;"> <a href="https://github.com/DUTIR-BioNLP/Taiyi-LLM">Github</a>
# <br>
# <br>
# </div>
# <br>
# <center><font size=4>ğŸš€<b style="color:red">Taiyi</b> is a bilingual (Chinese and English) biomedical large language model released by the Information Retrieval Laboratory of Dalian University of Technology.</font></center>
# <br>
# <center><font size=4>ğŸ‘†You can use the <b style="color: red">Enter</b> key to create a new line, and you can also hold down the <b style="color: red">Shift + Enter</b> keys to submit.</font></center>
# <br>
# """

BUTTON_DES = """
- <font size=3><b style="color:red">Retry</b>: If you are not satisfied with the current output of the model, you could use the Retry button to regenerate the response.</font>

- <font size=3><b style="color:red">Undo</b>: You can use the Undo button to revert the previous input.</font>

- <font size=3><b style="color:red">Clean</b>: Clear the history of the chat and start a new chat. If the topic of your conversation changes, it is recommended to use the Clean button to start a new chat.</font>

- <font size=3><b style="color:red">Submit</b>: Submit the text in the input box to the model.</font>
"""

# CONTRY_NUM = """
# <br>
# <center><a href="https://info.flagcounter.com/w63t"><img src="https://s11.flagcounter.com/mini/w63t/bg_FFFFFF/txt_000000/border_CCCCCC/flags_0/" alt="Flag Counter" border="0"></a></center>
# <center><font size=3>âš ï¸ Please read the <a href="https://github.com/DUTIR-BioNLP/Taiyi-LLM#disclaimer" rel="nofollow">Disclaimer</a> on Github before you strat trying Taiyi.</font></center>
# """


def check_ch_en(text):
    ch_pat = re.compile(u'[\u4e00-\u9fa5]') 
    en_pat = re.compile(r'[a-zA-Z]')
    has_ch = ch_pat.search(text)
    has_en = en_pat.search(text)
    if has_ch and has_en:
        return True 
    elif has_ch:
        return True 
    elif has_en:
        return True 
    else:
        return False

def clear_and_save_textbox(message: str):
    return '', message

def Delete_Specified_String(history):

    # åˆ›å»ºä¸€ä¸ªæ–°çš„äºŒç»´åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨ä¸åŒ…å«'ä½ çš„è¾“å…¥æ— æ•ˆ'å›ç­”çš„é—®ç­”å¯¹
    filtered_history = []

    # éå†åŸå§‹äºŒç»´åˆ—è¡¨
    for i, pair in enumerate(history):
        if i % 2 == 1:
            if pair["content"] != 'æ‚¨çš„è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥ï¼Œè°¢è°¢ï¼':
                filtered_history.append(history[i-1])
                filtered_history.append(history[i])
                

    # ç°åœ¨filtered_historyä¸­åŒ…å«ä¸åŒ…å«'ä½ çš„è¾“å…¥æ— æ•ˆ'å›ç­”çš„é—®ç­”å¯¹
    
    return filtered_history

def delete_prev_fn(history):
    try:
        _ = history.pop()
        user_message = history.pop()
    except IndexError:
        message = ''
    return history, user_message["content"] or ''


def remove_continuous_duplicate_sentences(text):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²æ–‡æœ¬ï¼Œä»¥å¥å·ã€é€—å·ã€åˆ†å·æˆ–æ¢è¡Œç¬¦ä¸ºåˆ†éš”ç¬¦
    sentences = re.split(r'([ã€‚,ï¼›ï¼Œ\n])', text)
    
    # åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„æ–‡æœ¬åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å»é™¤è¿ç»­é‡å¤å¥å­åçš„ç»“æœ
    new_sentences = [sentences[0]]  # å°†ç¬¬ä¸€ä¸ªå¥å­æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    
    # éå†å¥å­åˆ—è¡¨ï¼Œä»…æ·»åŠ ä¸ä¸å‰ä¸€ä¸ªå¥å­ç›¸åŒçš„å¥å­
    for i in range(2, len(sentences), 2):
        if sentences[i] != sentences[i - 2]:
            new_sentences.append(sentences[i - 1] + sentences[i])
    
    # é‡æ–°æ„å»ºæ–‡æœ¬ï¼Œä½¿ç”¨åŸå§‹æ ‡ç‚¹ç¬¦å·è¿æ¥å¥å­
    new_text = ''.join(new_sentences)
    
    return new_text


def generate(
    message: str,
    history,
    max_new_tokens: int,
    temperature: float,
    top_p: float
):
    # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå­—ç¬¦
    if not check_ch_en(message):
        generator = "æ‚¨çš„è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥ï¼Œè°¢è°¢ï¼"
        return history + [{"role": "user", "content": message}, {"role": "assistant", "content": generator}]

    history_list = []
    for i in range(0, len(history), 2):  # æ¯æ¬¡è·³ä¸¤æ­¥
        user_message = history[i]["content"]
        assistant_message = history[i + 1]["content"]
        # å°†æ¯å¯¹ [message, generator] åŠ å…¥åˆ°æ–°åˆ—è¡¨
        history_list.append([user_message, assistant_message])

    request_list = [{'query': message, 'history':history_list}]
    response_iterator = inference_stream_vllm(
                llm_engine,
                template,
                request_list,
                generation_config=VllmGenerationConfig(
                    repetition_penalty=1.05,
                    presence_penalty=True,
                    max_tokens=500,
                    temperature=0.3,
                    top_p=0.7,
                    top_k=20,
                    skip_special_tokens=True,
                    stop_token_ids=[151329, 151336, 151338]
                )
            )
    history = Delete_Specified_String(history)
    history.append({"role": "user", "content": message})
    history.append({"role": "assistant", "content": ''})
    for response_batch in response_iterator:
        for response in response_batch:
            # Print the answer
            answer = response.get('response', '')
            history[-1]['content'] = answer
            # time.sleep(0.05)
            yield history



# def change_textbox(choice):
#     global ROLE_TEMP
#     #æ ¹æ®ä¸åŒè¾“å…¥å¯¹è¾“å‡ºæ§ä»¶è¿›è¡Œæ›´æ–°
#     if choice == "ä¸­æ–‡":
#         ROLE_TEMP = 1
#         role_state = gr.update(visible=True, value="è¯·æ‰®æ¼”ä¸€ååŒ»ç–—ä¸“å®¶ï¼Œå›ç­”åç»­é—®é¢˜ã€‚")

#         message = role_state['value']
#         history = []
#         response = generate(message,history,500, 0.10, 0.9)
#         return response
#     elif choice == "English":
#         ROLE_TEMP = 2
#         role_state = gr.update(visible=True, value="Act as a medical expert to answer the questions.")

#         message = role_state['value']
#         history = []
#         response = generate(message,history,500, 0.10, 0.9)
#         return response
#     else:
#         ROLE_TEMP = 0
#         message = ""
#         history = []
#         return []


# def change_default_text():
#     return textbox.update(placeholder='Type a message...')


# def role_process():
#     if ROLE_TEMP == 1:
#         message = "è¯·æ‰®æ¼”ä¸€ååŒ»ç–—ä¸“å®¶ï¼Œå›ç­”åç»­é—®é¢˜ã€‚"
#         history = []
#         response = generate(message,history,500, 0.10, 0.9)
#         return response
#     elif ROLE_TEMP == 2:
#         message = "Act as a medical expert to answer the questions."
#         history = []
#         response = generate(message,history,500, 0.10, 0.9)
#         return response
#     elif ROLE_TEMP == 0:
#         message = ""
#         history = []
#         return []




# å¤„ç†ç¤ºä¾‹é—®é¢˜çš„å‡½æ•°
def process_example(message: str):
    generator = generate(message, [], 2048, 0.30, 0.7)
    
    return '', generator


custom_css = """
#banner-image {
    margin-left: auto;
    margin-right: auto;
    width: 65%;
    height: 65%
}

#

"""
with gr.Blocks(css=custom_css) as demo:
    
    gr.Image("/DUTIR/Taiyi2-test/demo/logo.png", elem_id="banner-image", show_label=False, container=False)
    # with gr.Column():
    #     gr.Markdown(DESCRIPTION)
    
    with gr.Accordion(label = 'âš ï¸ - About these buttons', open = False):
        gr.Markdown(BUTTON_DES)

    with gr.Group():
        chatbot = gr.Chatbot(
            label = 'Chatbot',
            type='messages',
            avatar_images=("/DUTIR/Taiyi2-test/demo/yonghu.png", "/DUTIR/Taiyi2-test/demo/jiqiren.png"),
            bubble_full_width=True    
        )
        
        # radio = gr.Radio(
        # ["ä¸­æ–‡", "English","None"],
        # value="None",
        # label="RolePlay(è§’è‰²æ‰®æ¼”)"
        # )
        textbox = gr.Textbox(
            container=False,
            show_label=False,
            placeholder="Please enter content...",
            lines=6
        )

        # radio.change(fn=change_textbox, inputs=radio, outputs=chatbot)
        # radio.change(fn=change_default_text, outputs=textbox)

                
    with gr.Row():
        retry_button = gr.Button('ğŸ”„  Retry', variant='secondary')
        undo_button = gr.Button('â†©ï¸ Undo', variant='secondary')
        clear_button = gr.Button('ğŸ—‘ï¸  Clear', variant='secondary')
        submit_button = gr.Button('ğŸš© Submit',variant='primary')


    saved_input = gr.State()

    with gr.Accordion(label = 'Advanced options', open = False):
        max_new_tokens = gr.Slider(
            label='Max new tokens',
            minimum=1,
            maximum=3000,
            step=1,
            value=2048,
            interactive=True,
        )
        temperature = gr.Slider(
            label='Temperature',
            minimum=0,
            maximum=1,
            step=0.05,
            value=0.30,
            interactive=True,
        )
        top_p = gr.Slider(
            label='Top-p (nucleus sampling)',
            minimum=0,
            maximum=1.0,
            step=0.1,
            value=0.7,
            interactive=True,
        )



    with gr.Accordion(label = 'Examples', open = False):
        gr.Examples(
        examples=[
            'æœ€è¿‘è‚šå­æ€»æ˜¯éšéšä½œç—›ï¼Œæ„Ÿè§‰èƒ€èƒ€çš„ï¼Œåƒä¸‹å»çš„ä¸œè¥¿éƒ½æ²¡æ³•å¸æ”¶ï¼Œèƒƒç–¼çš„ç‰¹åˆ«å‰å®³ï¼Œå¶å°”ä¼´æœ‰æ¶å¿ƒæƒ³åçš„æ„Ÿè§‰ï¼Œè¯·é—®æ˜¯ä»€ä¹ˆå›äº‹ï¼Ÿ',
            'What is the best treatment for sleep problems?'
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Question Answering'
        )

        gr.Examples(
        examples=[
            "æ‚£è€…ï¼šå°å­©å—å‡‰äº†ï¼Œæµæ¸…é¼»æ¶•ï¼Œå’³å—½ï¼Œåº”è¯¥æ˜¯é£å¯’å’³å—½ï¼Œå»è¯åº—ä¹°å“ªç§è¯å¥½å‘¢\nåŒ»ç”Ÿï¼šä½ å¥½ï¼Œå®å®å’³å—½ï¼Œæµæ¶•æ¯”è¾ƒå¸¸è§ï¼Œè¥¿åŒ»è§’åº¦ä¸Šå‘¼å¸é“æ„ŸæŸ“å¯èƒ½æ€§å¤§ï¼Œä¸­åŒ»ä¸Šå«åšé£å¯’å’³å—½ï¼Œè¯·é—®å®å®é™¤äº†å’³å—½æœ‰æ²¡æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶å‘¢ï¼Ÿä¾‹å¦‚å‘çƒ­ç­‰ï¼Œè¯·è¯¦ç»†æè¿°ä¸€ä¸‹ï¼Œæˆ‘å¥½å¸®ä½ è¯Šæ²»åˆ†æç—…æƒ…\næ‚£è€…ï¼šç²¾ç¥çŠ¶æ€å¥½ï¼Œä¹Ÿæ²¡æœ‰å‘çƒ­ï¼Œå°±æ˜¯å–‰å’™æœ‰ä¸€ç‚¹ç—›ï¼Œå’³å—½\nåŒ»ç”Ÿï¼šå…ˆå¸®ä½ åˆ†æä¸€ä¸‹ç—…æƒ…ï¼Œå®å®å—å‡‰ä¹‹åå…ç–«åŠ›é™ä½ï¼Œå°±ä¼šè¢«ç»†èŒæˆ–ç—…æ¯’ä¾µè¢­ä½“å†…ï¼Œæ°”é“åˆ†æ³Œç‰©å¢å¤šï¼Œæ”¯æ°”ç®¡å¹³æ»‘è‚Œç—‰æŒ›ï¼Œå’³å—½ï¼Œå’³ç—°ï¼Œå’½é€šã€‚\nåŒ»ç”Ÿï¼šç›®å‰æ²¡æœ‰å‘çƒ­ï¼Œå®å®ç—…æƒ…ä¸é‡ï¼Œä¸ç”¨è¿‡åˆ†ç´§å¼ çš„ã€‚\nåŒ»ç”Ÿï¼šæˆ‘å¸®æ¨èæ²»ç–—æ–¹æ³•\nåŒ»ç”Ÿï¼šå®å®ç›®å‰å¤šå¤§äº†ï¼Ÿæœ‰æ²¡æœ‰å†åŒ»é™¢çœ‹è¿‡ï¼Ÿåšè¿‡åŒ–éªŒæ£€æŸ¥\næ‚£è€…ï¼šå—¯\næ‚£è€…ï¼š7å²ï¼Œæ²¡å»åŒ»é™¢ï¼Œåšè¿‡å¾ˆå¤šæ£€æŸ¥ï¼Œå¹³å¸¸å°±æ˜¯çˆ±å’³å—½ï¼Œå–‰å“å‘ç‚\næ‚£è€…ï¼šåŒ»ç”Ÿè¯´ï¼Œæ‰æ¡ƒä½“åå¤§\nåŒ»ç”Ÿï¼šè¿‘æœŸè¿™æ¬¡æœ‰æ²¡æœ‰å»åŒ»é™¢çœ‹è¿‡ï¼Ÿåšè¿‡æ£€æŸ¥\nåŒ»ç”Ÿï¼šå¦‚æœå®å®æ²¡æœ‰å…¶ä»–ä¸é€‚ï¼Ÿå¯ä»¥å£æœæ°¨æº´ç´¢ï¼Œæ¡”è´åˆå‰‚æ•ˆæœå¥½\nåŒ»ç”Ÿï¼šå¦å¤–å¦‚æœæ¡ä»¶å…è®¸ï¼Œå¯ä»¥åšåšé›¾åŒ–å¸å…¥æ²»ç–—ç›´æ¥ä½œç”¨ä¸æ”¯æ°”ç®¡ç²˜è†œï¼Œæ•ˆæœæ›´ç›´æ¥\næ‚£è€…ï¼šä¸ç”¨åšé›¾åŒ–å§ï¼Œåƒç‚¹è¯å°±è¡Œäº†\nåŒ»ç”Ÿï¼šä¹Ÿå¯ä»¥å…ˆåƒè¯\næ‚£è€…ï¼šè¿‘æœŸæ²¡æœ‰å»è¿‡\nåŒ»ç”Ÿï¼šä½ ä»¬è¿™æ¬¡æ²¡æœ‰å»åŒ»é™¢çœ‹è¿‡ï¼Ÿ\næ‚£è€…ï¼šè¦åƒæ¶ˆç‚çš„å—\næ‚£è€…ï¼šæ²¡\næ‚£è€…ï¼šè¦åƒæ¶ˆç‚è¯å—\nåŒ»ç”Ÿï¼šä½ å¥½ï¼Œå¯ä»¥å…ˆä¸åƒçš„\næ‚£è€…ï¼šé‚£å®¶é‡Œæœ‰è’²åœ°è“ï¼Œå¯ä»¥åƒå—\næ‚£è€…ï¼šå£æœæ¶²\næ‚£è€…ï¼šå–‰å“ç—›è¦åƒå—\nåŒ»ç”Ÿï¼šå…ˆæ²»ç–—çœ‹çœ‹ï¼Œå¯ä»¥åƒçš„ï¼Œå‡å¦‚å®å®å‡ºç°å‘çƒ­æˆ–å’³å—½åŠ é‡ï¼ŒåŒ»é™¢å°±è¯Šï¼Œå¤æŸ¥è¡€å¸¸è§„å’Œèƒ¸ç‰‡ï¼Œé‚£ä¸ªæ—¶å€™å†è€ƒè™‘åŠ æŠ—ç”Ÿç´ \næ‚£è€…ï¼šå¦å¤–ä¹°ä¸ªæ­¢å’³çš„ï¼Œè¡Œå—\nåŒ»ç”Ÿï¼šæˆ‘ä»¬çš„è§‚ç‚¹æ˜¯å®å®å°ï¼Œå°½é‡å°‘åƒæ¶ˆç‚è¯ï¼Œå¯ä»¥å…ˆåƒé‚£å‡ ä¸ªè¯ä¸‰å¤©çœ‹çœ‹æ•ˆæœ\næ‚£è€…ï¼šå—¯è°¢è°¢\næ ¹æ®ä¸Šè¿°å¯¹è¯ï¼Œç»™å‡ºè¯Šç–—æŠ¥å‘Š\nè¯´æ˜ï¼šè¯Šç–—æŠ¥å‘Šåˆ†ä¸ºä¸»è¯‰, ç°ç—…å², è¾…åŠ©æ£€æŸ¥, æ—¢å¾€å², è¯Šæ–­, å»ºè®®è¿™å…­ä¸ªç« èŠ‚ã€‚"
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Medical Report Generation'
        )

        gr.Examples(
        examples=[
            'ä»ä¸‹é¢æ–‡æœ¬ä¸­è¯†åˆ«å‡ºæŒ‡å®šçš„å®ä½“ç±»å‹ï¼š\næ²»ç–—ä»¥é€‰ç”¨å¤§ç¯å†…é…¯ç±»æŠ—ç”Ÿç´ ï¼Œæ²™çœ¼è¡£åŸä½“è‚ºç‚ä¹Ÿå¯ç”¨ç£ºèƒºäºŒç”²åŸºå¼‚å”‘ï¼Œå¹´é•¿å„¿å’Œæˆäººç”¨æ°Ÿå–¹è¯ºé…®ç±»æ•ˆæœä¹Ÿå¾ˆå¥½ã€‚\nå®ä½“ç±»å‹ï¼šç–¾ç—…ï¼Œè¯ç‰©',
            'Extract the gene, disease entities from the following text:\nIdentification of a novel FBN1 gene mutation in a Chinese family with Marfan syndrome.'
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Name Entity Recognition'
        )

        gr.Examples(
        examples=[
            "ç»™å‡ºå¥å­ä¸­è¯ç‰©æ²»ç–—å…³ç³»ç±»å‹çš„å®ä½“å¯¹ï¼šæ…¢æ€§é˜»å¡æ€§è‚ºç–¾ç—…@å‡å°‘æ€¥æ€§åŠ é‡ï¼šæœ‰é«˜è´¨é‡çš„è¯æ®è¯å®ï¼ŒÎ²2 å—ä½“æ¿€åŠ¨å‰‚åœ¨å‡å°‘ 12-52 å‘¨æ€¥æ€§åŠ é‡æ–¹é¢æ¯”å®‰æ…°å‰‚æ›´æœ‰æ•ˆã€‚",
            "Find the relations of drug entity pairs in the textï¼š\nMitotane has been reported to accelerate the metabolism of warfarin by the mechanism of hepatic microsomal enzyme induction, leading to an increase in dosage requirements for warfarin. Therefore, physicians should closely monitor patients for a change in anticoagulant dosage requirements when administering Mitotane to patients on coumarin-type anticoagulants. In addition, Mitotane should be given with caution to patients receiving other drugs susceptible to the influence of hepatic enzyme induction.\nRelation Types: ADVISE, MECHANISM, EFFECT, INT"
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Relation Extraction'
        )

        gr.Examples(
        examples=[
            "æ‰¾å‡ºæŒ‡å®šçš„ä¸´åºŠå‘ç°äº‹ä»¶å±æ€§ï¼š\nå› æ‚£è€…éœ€æœŸæœ«è€ƒè¯•ï¼Œæ•…äºˆä»¥å£æœâ€œé›·è´æ‹‰å”‘é’ è‚ æº¶ç‰‡â€æ²»ç–—ï¼Œç°è…¹ç—›æƒ…å†µæ˜æ˜¾å¥½è½¬ã€‚\näº‹ä»¶æŠ½å–è¯´æ˜ï¼šä¸´åºŠå‘ç°äº‹ä»¶ç”±ä¸»ä½“è¯ï¼Œå‘ç”ŸçŠ¶æ€ï¼Œæè¿°è¯å’Œè§£å‰–éƒ¨ä½ç»„æˆ",
            'Input text: "Contaminated drinking water is responsible for causing diarrheal diseases that kill millions of people a year.\nEven Types: Treatment of disease, Cause of disease\nRole Types: Cause, Theme\nPlease extract events from the input text.'
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Event Extraction'
        )

        gr.Examples(
        examples=[
            "å°†ä¸‹é¢ä¸­æ–‡æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\nå…‰åŠ¨åŠ›ç–—æ³•ï¼ˆPDTï¼‰ä½œä¸ºä¸€ç§æ–°å…´çš„è‚¿ç˜¤æ²»ç–—æ‰‹æ®µï¼Œå› å…¶ä¸è‰¯ååº”è¾ƒå°‘ã€é¶å‘æ€§å¥½ã€å¯é‡å¤æ²»ç–—ç­‰ä¼˜ç‚¹ï¼Œå·²å¹¿æ³›åº”ç”¨äºä¸´åºŠå¤šç§è‚¿ç˜¤çš„æ²»ç–—ã€‚ç›¸æ¯”äºæ‰‹æœ¯ã€åŒ–ç–—åŠæ”¾ç–—ç­‰ä¼ ç»Ÿæ²»ç–—ç­–ç•¥ï¼Œå…‰åŠ¨åŠ›ç–—æ³•ä¸ä»…å¯æ€ä¼¤åŸä½è‚¿ç˜¤ï¼Œè¿˜å¯é€šè¿‡æ¿€æ´»æœºä½“çš„å…ç–«æ•ˆåº”å¯¹è½¬ç§»ç˜¤å‘æŒ¥æŠ‘åˆ¶ä½œç”¨ã€‚ç„¶è€Œï¼ŒPDTè¯±å¯¼å…ç–«æ•ˆåº”çš„é«˜ä½å—å¤šç§å› ç´ å½±å“ï¼ŒåŒ…æ‹¬å…‰æ•å‰‚åœ¨ç»†èƒå†…çš„å®šä½å’Œå‰‚é‡ã€å…‰å‚æ•°ã€è‚¿ç˜¤å†…çš„æ°§æµ“åº¦ã€å…ç–«åŠŸèƒ½çš„å®Œæ•´æ€§ç­‰ã€‚æœ¬æ–‡é’ˆå¯¹PDTä»‹å¯¼æŠ—è‚¿ç˜¤å…ç–«æ•ˆåº”çš„ç›¸å…³æœºåˆ¶ï¼Œä»¥åŠPDTå…ç–«æ•ˆåº”çš„ä¸»è¦å½±å“å› ç´ è¿›è¡Œç»¼è¿°ï¼Œä»¥æ¢è®¨PDTç”¨äºè‚¿ç˜¤æ²»ç–—çš„æœªæ¥å‘å±•æ–¹å‘ã€‚",
            "Translate the following text into Chinese:\nNon-Alcoholic Fatty Liver Disease (NAFLD) is defined as increased liver fat percentage, and is the most common chronic liver disease in children. Rather than NAFLD, Metabolic-Associated Fatty Liver Disease (MAFLD), defined as increased liver fat with presence of adverse cardio-metabolic measures, might have more clinical relevance in children. We assessed the prevalence, risk-factors and cardio-metabolic outcomes of MAFLD at school-age."
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Machine Translation'
        )

        gr.Examples(
        examples=[
            "è¯·ç»™ä¸‹é¢æ‘˜è¦èµ·æ ‡é¢˜ï¼š\næ°”ç®¡é£Ÿç®¡ç˜˜æ˜¯æŒ‡æ°”ç®¡æˆ–æ”¯æ°”ç®¡ä¸é£Ÿç®¡ä¹‹é—´çš„ç—…ç†æ€§ç˜˜é“ï¼ŒåŒ…æ‹¬æ°”ç®¡-é£Ÿç®¡ç˜˜å’Œæ”¯æ°”ç®¡-é£Ÿç®¡ç˜˜ï¼Œä¸´åºŠä»¥æ°”ç®¡-é£Ÿç®¡ç˜˜è¾ƒå¤šè§ã€‚æ°”ç®¡é£Ÿç®¡ç˜˜è‡´ç—…åŸå› è¾ƒå¤šï¼Œå¯å¼•èµ·ä¸¥é‡çš„å¹¶å‘ç—‡ï¼Œæ˜¯å¯¹æ‚£è€…ç”Ÿæ´»è´¨é‡å½±å“æ˜¾è‘—ã€æ²»ç–—å›°éš¾å’Œç—…æ­»ç‡è¾ƒé«˜çš„ç–¾ç—…ã€‚æ°”ç®¡é£Ÿç®¡ç˜˜ç›®å‰æ²»ç–—æ–¹å¼è¾ƒå¤šï¼Œä½†å¤šæ•°ç–—æ•ˆæ¬ ä½³ï¼Œå¯¹æ–°å…´æ²»ç–—æ‰‹æ®µçš„éœ€æ±‚è¿«åˆ‡ã€‚èƒ¸è…¹éƒ¨Xçº¿æ‘„å½±æ£€å‡ºé¼»èƒƒç®¡æ»ç•™æ˜¯æ°”ç®¡é£Ÿç®¡ç˜˜è¯Šæ–­çš„é‡‘æ ‡å‡†ï¼Œå…¶ä¸»è¦æ²»ç–—æ–¹æ³•åŒ…æ‹¬å¤–ç§‘æ‰‹æœ¯æ²»ç–—ã€æ”¯æ¶ç½®å…¥ã€å±€éƒ¨ç”Ÿç‰©èƒ¶æ°´å°é—­ã€å¹²ç»†èƒæ²»ç–—ç­‰ã€‚æœ¬æ–‡ç»¼è¿°è¿‘å¹´æ°”ç®¡é£Ÿç®¡ç˜˜è¯Šæ–­ä¸æ²»ç–—çš„ä¸»è¦ç ”ç©¶è¿›å±•ï¼Œæ—¨åœ¨ä¸ºè¯¥ç—…çš„ä¸´åºŠè¯Šæ²»æä¾›å‚è€ƒã€‚",
            "Output a title for the following abstract:\nThe incidence of diabetes mellitus has been increasing, prompting the search for non-invasive diagnostic methods. Although current methods exist, these have certain limitations, such as low reliability and accuracy, difficulty in individual patient adjustment, and discomfort during use. This paper presents a novel approach for diagnosing diabetes using high-frequency ultrasound (HFU) and a convolutional neural network (CNN). This method is based on the observation that glucose in red blood cells (RBCs) forms glycated hemoglobin (HbA1c) and accumulates on its surface. The study incubated RBCs with different glucose concentrations, collected acoustic reflection signals from them using a custom-designed 90-MHz transducer, and analyzed the signals using a CNN. The CNN was applied to the frequency spectra and spectrograms of the signal to identify correlations between changes in RBC properties owing to glucose concentration and signal features. The results confirmed the efficacy of the CNN-based approach with a classification accuracy of 0.98. This non-invasive diagnostic technology using HFU and CNN holds promise for in vivo diagnosis without the need for blood collection."
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Title Generation'
        )

        gr.Examples(
        examples=[
            "ç°æœ‰ä»¥ä¸‹æ–‡æœ¬ï¼š\næ²»çš®è‚¤ç—…è´¹ç”¨å¤§æ¦‚å¤šå°‘ï¼Ÿ\nè¯·å°†ä¸Šè¿°æ–‡æœ¬åˆ†ç±»è‡³æŒ‡å®šç±»åˆ«ä¸­ï¼šåŒ»ç–—è´¹ç”¨ï¼Œåæœè¡¨è¿°ï¼ŒæŒ‡æ ‡è§£è¯»ï¼Œç—…æƒ…è¯Šæ–­ï¼Œå°±åŒ»å»ºè®®ï¼Œç–¾ç—…æè¿°ï¼Œå…¶ä»–ï¼Œæ²»ç–—æ–¹æ¡ˆï¼Œç—…å› åˆ†æï¼ŒåŠŸæ•ˆä½œç”¨ï¼Œæ³¨æ„äº‹é¡¹",
            'Document triage: "Will my mask from sherwin williams paint store with filters protect me from corona virus along with paint fumes?"\nLabels: patient, doctor'
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Text Classification'
        )

        gr.Examples(
        examples=[
            "è¯­å¥1ï¼šä¹™è‚å°äºŒé˜³ä¼šè½¬æˆå°ä¸‰é˜³å—ï¼Ÿ\nè¯­å¥2ï¼šä¹™è‚å°ä¸‰é˜³ä¼šä¸ä¼šè½¬æˆè‚ç¡¬åŒ–ã€è‚ç™Œï¼Ÿ\nè¯·ä»ä¸‹é¢é€‰é¡¹ä¸­è¯„ä¼°è¿™æ®µæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼šè¯­ä¹‰ä¸ç›¸åŒï¼Œè¯­ä¹‰ç›¸åŒ",
            "1. How can someone's happiness level affect someone's health?\n2. Can staying happy improve my health? What specific steps should I take?\nAssess the semantic similarity of the text pairs based on the following labels: dissimilar, similar"
        ],
        inputs=textbox,
        outputs=[textbox, chatbot],
        fn=process_example,
        cache_examples=False,
        label='Text Semantic Similarity'
        )


    textbox.submit(
        fn=clear_and_save_textbox,
        inputs=textbox,
        outputs=[textbox, saved_input],
        api_name=False,
        queue=False,
    ).success(
        fn=generate,
        inputs=[
            saved_input,
            chatbot,
            max_new_tokens,
            temperature,
            top_p,
        ],
        outputs=chatbot,
        api_name=False,
    )

    button_event_preprocess = submit_button.click(
        fn=clear_and_save_textbox,
        inputs=textbox,
        outputs=[textbox, saved_input],
        api_name=False,
        queue=False,
    ).success(
        fn=generate,
        inputs=[
            saved_input,
            chatbot,
            max_new_tokens,
            temperature,
            top_p,
        ],
        outputs=chatbot,
        api_name=False,
    )

    retry_button.click(
        fn=delete_prev_fn,
        inputs=chatbot,
        outputs=[chatbot, saved_input],
        api_name=False,
        queue=False,
    ).then(
        fn=generate,
        inputs=[
            saved_input,
            chatbot,
            max_new_tokens,
            temperature,
            top_p,
        ],
        outputs=chatbot,
        api_name=False,
    )

    undo_button.click(
        fn=delete_prev_fn,
        inputs=chatbot,
        outputs=[chatbot, saved_input],
        api_name=False,
        queue=False,
    ).then(
        fn=lambda x: x,
        inputs=[saved_input],
        outputs=textbox,
        api_name=False,
        queue=False,
    )


    clear_button.click(
        fn=lambda: ([], ''),
        outputs=[chatbot, saved_input],
        queue=False,
        api_name=False,
    )

    # gr.HTML(CONTRY_NUM)


if __name__ == "__main__":
    demo.queue().launch()
